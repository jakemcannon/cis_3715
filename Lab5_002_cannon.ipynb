{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Lab 5: Logistic Regression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this assignment, we will learn the Logistic Regression model.\n",
    "\n",
    "First, please study the given example, which uses the logistic regression model for the breast cancer classification task. In this example, you will learn how to preprocess data, how to train the model, and how to evaluate the model.\n",
    "\n",
    "Based on the given example, your task is to use the logistic regression model to predict the presence of heart disease.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Example"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.1 Load the breast cancer data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here, we use the [breast cancer](https://scikit-learn.org/stable/modules/generated/sklearn.datasets.load_breast_cancer.html#sklearn.datasets.load_breast_cancer) dataset in sklearn. It is a binary classification dataset. Each sample has 30 numerical features, which can be found in [7.1.7](https://scikit-learn.org/stable/datasets/toy_dataset.html)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "#samples: 569, #features: 30\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn import datasets\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.metrics import recall_score\n",
    "from sklearn.metrics import precision_score\n",
    "from random import shuffle\n",
    "import random\n",
    "random.seed(123)\n",
    "\n",
    "X, y = datasets.load_breast_cancer(return_X_y=True)\n",
    "print(\"#samples: {}, #features: {}\".format(X.shape[0], X.shape[1]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.2 Split the data into two subsets and normalize the features of samples\n",
    "\n",
    "Here, we use 69 samples as the testing set and use the remained samples to train the logistic regression model. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_val: 500, test: 69\n"
     ]
    }
   ],
   "source": [
    "X_train_val, X_test, y_train_val, y_test = train_test_split(X, y, \n",
    "                                                            test_size=0.12, \n",
    "                                                            random_state=0)\n",
    "print(\"train_val: {}, test: {}\".format(X_train_val.shape[0], X_test.shape[0]))\n",
    "\n",
    "normalizer = StandardScaler()\n",
    "X_train_val = normalizer.fit_transform(X_train_val)\n",
    "X_test = normalizer.transform(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.3 Train the logistic regression model and select the hyperparameter with cross-validation\n",
    "\n",
    "Here, we use the following logistic regression model to do cancer classification. \n",
    "\n",
    "\\begin{equation}\n",
    "\t\\min_{\\mathbf{w}} \\sum_{i=1}^{n}\\{\\log(1+\\exp(\\mathbf{w}^T\\mathbf{x}_i))-y_i\\mathbf{w}^T\\mathbf{x}_i \\} + \\lambda\\|\\mathbf{w}\\|_2^2\n",
    "\\end{equation}\n",
    "\n",
    "We need to learn the model parameter $\\mathbf{w}$. However, with different hyperparameters $\\lambda$, we can get different model parameter $\\mathbf{w}$, resulting in different prediction performance. Here, we use the 5-fold cross-validation to select the hyperparameter $\\lambda$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[380 468 145   2 282 103 148 312 130 411 168 204 113 132 418 270 351 157\n",
      "  451 339 288 277 354  48 318 303 314 234  95 304 271 434 173 357 495 133\n",
      "  431  39 490 310 317 471  23 426 224 286  20 365 255 216 405  79 228 445\n",
      "  189 184 243 358 276 218 488  60 438 159 167 349  89 121 333  51   9 482\n",
      "  152 416 379 306 111 185 340 489 475  93  84 376 291 158 250 323 406 460\n",
      "   50 433 372  66 108 465  71 298 369 437]\n",
      " [211  11 110 142  28  59 163  38  24 205 440 140 177 252 235 245 242  25\n",
      "   21 217 160 231  77 151  54 345 280 257 456 308 331  58 360 179 464 388\n",
      "  129 285 347  56 387 169  36 138 319 296 246 122  33 127 109 363 183 196\n",
      "  422  86 400 297 346 116  63  88 477 144 112 362 399 334  62 353 146 373\n",
      "   27  76 260 150 210 195 290  82 154 432 320 361  75  17  94 238 143 469\n",
      "   67 225 391 106  15  97  46  49 192 226]\n",
      " [114 302 356  91  80 107 329 209 384 409  13 176 299 483 295 491 332 292\n",
      "  153 202 268   1 417 313 375 128 352  57 408 254 382 390 377 328 213 182\n",
      "   65   7 315 101 187 126 123 394 201 251 494 239 383 367 237  34 307 141\n",
      "  403 344 162  43 118 498  99 392 102 258 100  41 281 364 492 448 164 104\n",
      "  124 259 355 458 484 115 309 338  53 381 442  70 284 263 419 166 441 481\n",
      "  335 219 155 294 230 378 476 232 480  31]\n",
      " [343 197 301  85  61 264 446 273 455 188 199 452  74 443 423 395 265  29\n",
      "   40 120 190  73 348 415 474 337  12 178 212 402 478 412 241 454 165  14\n",
      "  206 325 279 398 366 462   4 221 421 389 181 413  32 316 493 473 215 324\n",
      "  425 139 424 385 131 453  98 470  68   5 459 236 466 227 487  78  90 439\n",
      "  278 119 368 322 253 147 435  30 397 256 272 207 117 180 430 186 321  45\n",
      "  300  96   8 401 450 198 233 370  37 200]\n",
      " [283 479 171  87 134 336 249  42 371  92 427 386  16 261 191 214 342 266\n",
      "  248 467 457 407 326 275 350 222 262 330 444 203   6 472 414 289 269 327\n",
      "  311 420 105 247 410 267 175 156 496  18 428 240 135 244 293 220 149  10\n",
      "  404  64  72 341  47  22  52 229 374 161   3  35 193 305 449 497 396 223\n",
      "  463   0  83 125 359 485 486 172  69  81 499 436 174 170 287 274 194  19\n",
      "  447 461 429  55 136 208 393  44 137  26]]\n",
      "reg_coeff: 10.0, acc: 0.970\n",
      "reg_coeff: 2.0, acc: 0.978\n",
      "reg_coeff: 1.0, acc: 0.972\n",
      "reg_coeff: 0.2, acc: 0.968\n",
      "reg_coeff: 0.1, acc: 0.968\n"
     ]
    }
   ],
   "source": [
    "# here we use 5-fold cross-validation\n",
    "folds = 5\n",
    "\n",
    "# get the number of samples in the training and validation set\n",
    "num_train_val = X_train_val.shape[0] \n",
    "\n",
    "# shuffle the index of samples in the train_val set\n",
    "index_of_samples = np.arange(num_train_val) \n",
    "shuffle(index_of_samples)\n",
    "\n",
    "# split the index of the train_valid set into 5 folds\n",
    "index_of_folds = index_of_samples.reshape(folds, -1)\n",
    "print(index_of_folds)\n",
    "\n",
    "# potential hyperparameters. \n",
    "#These hyperparameters are just used for illustration. \n",
    "#You should try more hyperparameters to get a good model.\n",
    "#The hyperparameters must be nonnegative!\n",
    "regularization_coefficient = [0.1, 0.5, 1.0, 5.0, 10.0]\n",
    "\n",
    "best_acc = 0.0\n",
    "best_reg = 0.0\n",
    "\n",
    "for reg in regularization_coefficient:\n",
    "    \n",
    "    # 5-fold cross-validation\n",
    "    sum_acc = 0.0\n",
    "    for fold in range(folds):\n",
    "        \n",
    "        index_of_folds_temp = index_of_folds.copy()\n",
    "        \n",
    "        valid_index = index_of_folds_temp[fold,:].reshape(-1) #get the index of the validation set\n",
    "        train_index = np.delete(index_of_folds_temp, fold, 0).reshape(-1) #get the index of the training set\n",
    "        \n",
    "        # training set\n",
    "        X_train = X_train_val[train_index]\n",
    "        y_train = y_train_val[train_index]\n",
    "        \n",
    "        # validation set\n",
    "        X_valid = X_train_val[valid_index]\n",
    "        y_valid = y_train_val[valid_index]\n",
    "                \n",
    "        # build the model with different hyperparameters\n",
    "        clf = LogisticRegression(penalty='l2', C=reg, solver='lbfgs')\n",
    "        \n",
    "        #train the model with the training set\n",
    "        clf.fit(X_train, y_train)\n",
    "        \n",
    "        y_valid_pred = clf.predict(X_valid)\n",
    "        acc = accuracy_score(y_valid, y_valid_pred)\n",
    "        \n",
    "        sum_acc += acc\n",
    "    \n",
    "    cur_acc = sum_acc / folds\n",
    "    \n",
    "    print(\"reg_coeff: {}, acc: {:.3f}\".format(1.0/reg, cur_acc))\n",
    "    \n",
    "    # store the best hyperparameter\n",
    "    if cur_acc > best_acc:\n",
    "        best_acc = cur_acc\n",
    "        best_reg = reg"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.4 Evaluate the learned model\n",
    "\n",
    "After getting the best hyperparameter $\\lambda$, we retrain the model with the train_val set. Then, we evaluate this  model on the testing set. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy: 1.000, recall: 1.000, precision: 1.000, f1: 1.000,\n"
     ]
    }
   ],
   "source": [
    "# retrain the model\n",
    "clf = LogisticRegression(penalty='l2', C=best_reg, solver='lbfgs')\n",
    "clf.fit(X_train_val, y_train_val)\n",
    "\n",
    "# evaluate the model on the testing set\n",
    "y_test_pred = clf.predict(X_test)\n",
    "\n",
    "\n",
    "acc = accuracy_score(y_test, y_test_pred)\n",
    "f1 = f1_score(y_test, y_test_pred)\n",
    "recall = recall_score(y_test, y_test_pred)\n",
    "precision = precision_score(y_test, y_test_pred)\n",
    "\n",
    "\n",
    "print(\"accuracy: {:.3f}, recall: {:.3f}, precision: {:.3f}, f1: {:.3f},\".format(acc, recall, precision, f1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Task\n",
    "\n",
    "Here, we use the [heart disease](./heart.csv) dataset. Each sample has the following feature: \n",
    "\n",
    "* age\n",
    "* sex\n",
    "* chest pain type (4 values)\n",
    "* resting blood pressure\n",
    "* serum cholestoral in mg/dl\n",
    "* fasting blood sugar > 120 mg/dl\n",
    "* resting electrocardiographic results (values 0,1,2)\n",
    "* maximum heart rate achieved\n",
    "* exercise induced angina\n",
    "* oldpeak = ST depression induced by exercise relative to rest\n",
    "* the slope of the peak exercise ST segment\n",
    "* number of major vessels (0-3) colored by flourosopy\n",
    "* thal: 3 = normal; 6 = fixed defect; 7 = reversable defect\n",
    "\n",
    "The last column refers to the presence of heart disease in the patient.\n",
    "\n",
    "The task is to predict whether a person has the heart disease. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.1 Preprocess the raw data\n",
    "\n",
    "* Check whether there are missing values\n",
    "* Check whether theare are cateogrical features\n",
    "* Check whether this dataset is balanced or not (use the bar plot to visualize the number of positive and negative samples)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "age         0\n",
      "sex         0\n",
      "cp          0\n",
      "trestbps    0\n",
      "chol        0\n",
      "fbs         0\n",
      "restecg     0\n",
      "thalach     0\n",
      "exang       0\n",
      "oldpeak     0\n",
      "slope       0\n",
      "ca          0\n",
      "thal        0\n",
      "target      0\n",
      "dtype: int64\n",
      "     age  sex  cp  trestbps  chol  fbs  restecg  thalach  exang  oldpeak  \\\n",
      "0     63    1   3       145   233    1        0      150      0      2.3   \n",
      "1     37    1   2       130   250    0        1      187      0      3.5   \n",
      "2     41    0   1       130   204    0        0      172      0      1.4   \n",
      "3     56    1   1       120   236    0        1      178      0      0.8   \n",
      "4     57    0   0       120   354    0        1      163      1      0.6   \n",
      "..   ...  ...  ..       ...   ...  ...      ...      ...    ...      ...   \n",
      "298   57    0   0       140   241    0        1      123      1      0.2   \n",
      "299   45    1   3       110   264    0        1      132      0      1.2   \n",
      "300   68    1   0       144   193    1        1      141      0      3.4   \n",
      "301   57    1   0       130   131    0        1      115      1      1.2   \n",
      "302   57    0   1       130   236    0        0      174      0      0.0   \n",
      "\n",
      "     slope  ca  thal  target  \n",
      "0        0   0     1       1  \n",
      "1        0   0     2       1  \n",
      "2        2   0     2       1  \n",
      "3        2   0     2       1  \n",
      "4        2   0     2       1  \n",
      "..     ...  ..   ...     ...  \n",
      "298      1   0     3       0  \n",
      "299      1   0     3       0  \n",
      "300      1   2     3       0  \n",
      "301      1   1     3       0  \n",
      "302      1   1     2       0  \n",
      "\n",
      "[303 rows x 14 columns]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<BarContainer object of 2 artists>"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# your code\n",
    "df = pd.read_csv('heart.csv')\n",
    "\n",
    "# 0 missing values\n",
    "print(df.isnull().sum())\n",
    "\n",
    "# no categorical features\n",
    "print(df)\n",
    "\n",
    "# The data appears to be balanced\n",
    "plt.bar(df['target'].value_counts().index, df['target'].value_counts().values, tick_label=['unhealthy', 'healthy'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.2 Split the data into two subsets and normalize the features of samples\n",
    "\n",
    "* Split the dataset into the train_val set and testing set. \n",
    "* Normalize features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_val: 260, test: 43\n"
     ]
    }
   ],
   "source": [
    "## your code\n",
    "X = df.drop('target', axis=1).values\n",
    "y = df['target'].values\n",
    "X_train_val, X_test, y_train_val, y_test = train_test_split(X, y, \n",
    "                                                            test_size=0.14, \n",
    "                                                            random_state=0)\n",
    "print(\"train_val: {}, test: {}\".format(X_train_val.shape[0], X_test.shape[0]))\n",
    "\n",
    "normalizer = StandardScaler()\n",
    "X_train_val = normalizer.fit_transform(X_train_val)\n",
    "X_test = normalizer.transform(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.3 Train the logistic regression model and select the hyperparameter with cross-validation\n",
    "\n",
    "\\begin{equation}\n",
    "\t\\min_{\\mathbf{w}} \\sum_{i=1}^{n}\\{\\log(1+\\exp(\\mathbf{w}^T\\mathbf{x}_i))-y_i\\mathbf{w}^T\\mathbf{x}_i \\} + \\lambda\\|\\mathbf{w}\\|_2^2\n",
    "\\end{equation}\n",
    "\n",
    "* Use the 10-fold cross-validation to select the hyperparameter $\\lambda$.\n",
    "* Search $\\lambda$ from $\\{10^{-5}, 10^{-4}, 10^{-3}, 10^{-2}, 10^{-1}, 1, 10, 20, 50, 100\\}$\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 73  76 127 182   1 209 132 138  14  34  38  31  70 225 149 247  19 191\n",
      "  213 146 164  22  74 167 193  10]\n",
      " [154 173  87   9 188  21  77 216 204  93 179 125 248 250 145 124  15   0\n",
      "   75 233 139 137 186  42   3  82]\n",
      " [254 141  45  48  96  13 242   5   7  88  79 161 189  44 114  40 117 175\n",
      "   33 255 150 207 249 133 122 206]\n",
      " [128 101 237 243 253 103  12 106 151  32  81 123 170  69  29 126  99  17\n",
      "  174 202  59 215 131 185 220  41]\n",
      " [172 168 144  91 210 259 192 194 190  50 252 211  64  43  65 159  61  71\n",
      "   55  47  23 162 120 100 227 200]\n",
      " [158 221  72 166 157 217 163  18 181  30 239 214 184 231 246   8 155  86\n",
      "  104 112 143 135  20  83  85 136]\n",
      " [148 109 236 169 195 134 240 176  95  78   4 153 226  57 147  66  67  89\n",
      "  201  24 199  68 121 118 234 244]\n",
      " [130 187 129 140 228 222 107 177 232  58  46 203 110   6 196  16  90 165\n",
      "   27   2 197  92  53  51  39  63]\n",
      " [178 218 205 102 116 230  62 257 212  97 241  60 111 229 142 223  98 256\n",
      "   37  49  52 171 224  26 119 113]\n",
      " [ 25 156  94 208 108  36 180 238 115  56 251  28  54  35 235 105 245 152\n",
      "  219 258 160 198  11 183  84  80]]\n",
      "reg_coeff: 99999.99999999999, acc: 0.554\n",
      "reg_coeff: 10000.0, acc: 0.554\n",
      "reg_coeff: 1000.0, acc: 0.692\n",
      "reg_coeff: 100.0, acc: 0.831\n",
      "reg_coeff: 10.0, acc: 0.831\n",
      "reg_coeff: 1.0, acc: 0.831\n",
      "reg_coeff: 0.1, acc: 0.831\n",
      "reg_coeff: 0.05, acc: 0.831\n",
      "reg_coeff: 0.02, acc: 0.831\n",
      "reg_coeff: 0.01, acc: 0.831\n"
     ]
    }
   ],
   "source": [
    "## your code\n",
    "folds = 10\n",
    "\n",
    "# get the number of samples in the training and validation set\n",
    "num_train_val = X_train_val.shape[0] \n",
    "\n",
    "# shuffle the index of samples in the train_val set\n",
    "index_of_samples = np.arange(num_train_val) \n",
    "shuffle(index_of_samples)\n",
    "\n",
    "# split the index of the train_valid set into 5 folds\n",
    "index_of_folds = index_of_samples.reshape(folds, -1)\n",
    "print(index_of_folds)\n",
    "\n",
    "# potential hyperparameters. \n",
    "regularization_coefficient = [0.00001, 0.0001, 0.001, 0.01, 0.1, 1, 10, 20, 50, 100]\n",
    "\n",
    "\n",
    "best_acc = 0.0\n",
    "best_reg = 0.0\n",
    "\n",
    "for reg in regularization_coefficient:\n",
    "    \n",
    "    sum_acc = 0.0\n",
    "    for fold in range(folds):\n",
    "        \n",
    "        index_of_folds_temp = index_of_folds.copy()\n",
    "        \n",
    "        valid_index = index_of_folds_temp[fold,:].reshape(-1)\n",
    "        train_index = np.delete(index_of_folds_temp, fold, 0).reshape(-1)\n",
    "        \n",
    "        X_train = X_train_val[train_index]\n",
    "        y_train = y_train_val[train_index]\n",
    "        \n",
    "        X_valid = X_train_val[valid_index]\n",
    "        y_valid = y_train_val[valid_index]\n",
    "        \n",
    "        clf = LogisticRegression(penalty='l2', C=reg, solver='lbfgs')\n",
    "        clf.fit(X_train, y_train)\n",
    "        \n",
    "        y_valid_pred = clf.predict(X_valid)\n",
    "        acc = accuracy_score(y_valid, y_valid_pred)\n",
    "        \n",
    "        sum_acc += acc\n",
    "    \n",
    "    cur_acc = sum_acc / folds\n",
    "    \n",
    "    print(\"reg_coeff: {}, acc: {:.3f}\".format(1.0/reg, cur_acc))\n",
    "    \n",
    "    # store the best hyperparameter\n",
    "    if cur_acc > best_acc:\n",
    "        best_acc = cur_acc\n",
    "        best_reg = reg\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.4 Evaluate the learned model\n",
    "\n",
    "* Report the prediction accuracy, recall, precision, and F1 score.\n",
    "\n",
    "* Use the bar plot to visulaize the elements of the learned model parameter vector $\\mathbf{w}$. Some elements  have larger absolute values, while the others do not. Try to explain this phenomenon. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy: 0.837, recall: 0.857, precision: 0.818, f1: 0.837,\n"
     ]
    }
   ],
   "source": [
    "## your code\n",
    "# retrain the model\n",
    "clf = LogisticRegression(penalty='l2', C=best_reg, solver='lbfgs')\n",
    "clf.fit(X_train_val, y_train_val)\n",
    "\n",
    "# evaluate the model on the testing set\n",
    "y_test_pred = clf.predict(X_test)\n",
    "\n",
    "\n",
    "acc = accuracy_score(y_test, y_test_pred)\n",
    "f1 = f1_score(y_test, y_test_pred)\n",
    "recall = recall_score(y_test, y_test_pred)\n",
    "precision = precision_score(y_test, y_test_pred)\n",
    "\n",
    "\n",
    "print(\"accuracy: {:.3f}, recall: {:.3f}, precision: {:.3f}, f1: {:.3f},\".format(acc, recall, precision, f1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<BarContainer object of 13 artists>"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAmIAAAHSCAYAAABPdKcOAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjMuMywgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/Il7ecAAAACXBIWXMAAAsTAAALEwEAmpwYAAAiX0lEQVR4nO3dfZhmZ10n+O+PdBIQBBLSYgyEjhAVHGbCUARZXBQIDLNZSRhBgjqGa2GzOoOsujiEgWHYjMy24gzujjhDwEgU5FUjLYmEkPA2kEAaCHk1JIZGEnmJvLjyTuA3fzynzUOlqiudp7rvqs7nc1111Tn3uc85vzrPc05/6z6nnq7uDgAA+99dRhcAAHBnJYgBAAwiiAEADCKIAQAMIogBAAwiiAEADLJldAF3xBFHHNHbtm0bXQYAwJo+/OEP/213b11p2aYMYtu2bcvOnTtHlwEAsKaq+uRqy9yaBAAYRBADABhEEAMAGEQQAwAYRBADABhEEAMAGEQQAwAYRBADABhEEAMAGEQQAwAYRBADABhEEAMAGEQQAwAYRBADABhEEAMAGEQQAwAYRBADABhEEAMAGGTL6AI48Gw7/dyh+9+1/cSh+weA28uIGADAIIIYAMAgghgAwCCCGADAIIIYAMAgghgAwCCCGADAIIIYAMAgghgAwCCCGADAIIIYAMAgghgAwCCCGADAIIIYAMAgghgAwCCCGADAIOsSxKrqSVV1bVVdX1Wnr7D85VV12fT18ar60tyyb88t27Ee9QAAbAZbFt1AVR2U5BVJnpDkxiSXVtWO7r56d5/u/tW5/r+c5GFzm/hadx+3aB0AAJvNeoyIHZ/k+u6+obu/meQNSU7aQ/9nJHn9OuwXAGBTW48gdlSST83N3zi13UZVPSDJMUkummu+a1XtrKpLqurk1XZSVadN/XbefPPN61A2AMBY+/th/VOSvKW7vz3X9oDuXkrys0l+p6oeuNKK3X1mdy9199LWrVv3R60AAPvUegSxm5Lcf27+flPbSk7JstuS3X3T9P2GJO/Odz8/BgBwwFqPIHZpkmOr6piqOiSzsHWbv36sqh9JcliSi+faDquqQ6fpI5I8OsnVy9cFADgQLfxXk919S1U9J8n5SQ5KclZ3X1VVZyTZ2d27Q9kpSd7Q3T23+oOTvLKqvpNZKNw+/9eWAAAHsoWDWJJ093lJzlvW9uJl8y9ZYb0PJHnoetQAALDZ+GR9AIBBBDEAgEEEMQCAQQQxAIBBBDEAgEEEMQCAQQQxAIBBBDEAgEEEMQCAQQQxAIBBBDEAgEEEMQCAQQQxAIBBBDEAgEEEMQCAQQQxAIBBBDEAgEEEMQCAQQQxAIBBBDEAgEEEMQCAQQQxAIBBBDEAgEEEMQCAQQQxAIBBBDEAgEEEMQCAQQQxAIBBBDEAgEEEMQCAQQQxAIBBBDEAgEEEMQCAQQQxAIBBBDEAgEEEMQCAQQQxAIBBBDEAgEEEMQCAQQQxAIBBBDEAgEEEMQCAQQQxAIBBBDEAgEEEMQCAQQQxAIBB1iWIVdWTquraqrq+qk5fYfkzq+rmqrps+nr23LJTq+q66evU9agHAGAz2LLoBqrqoCSvSPKEJDcmubSqdnT31cu6vrG7n7Ns3cOT/PskS0k6yYendb+4aF0AABvdeoyIHZ/k+u6+obu/meQNSU66nev+syQXdPcXpvB1QZInrUNNAAAb3noEsaOSfGpu/sapbbmfrqrLq+otVXX/vVwXAOCAs78e1v/zJNu6+x9nNup19t5uoKpOq6qdVbXz5ptvXvcCAQD2t/UIYjcluf/c/P2mtn/Q3Z/v7m9Ms69O8vDbu+7cNs7s7qXuXtq6des6lA0AMNZ6BLFLkxxbVcdU1SFJTkmyY75DVR05N/vkJNdM0+cneWJVHVZVhyV54tQGAHDAW/ivJrv7lqp6TmYB6qAkZ3X3VVV1RpKd3b0jyXOr6slJbknyhSTPnNb9QlX9h8zCXJKc0d1fWLQmAIDNYOEgliTdfV6S85a1vXhu+gVJXrDKumclOWs96gAA2Ex8sj4AwCCCGADAIIIYAMAgghgAwCCCGADAIIIYAMAgghgAwCCCGADAIIIYAMAgghgAwCCCGADAIIIYAMAgghgAwCCCGADAIIIYAMAgghgAwCCCGADAIIIYAMAgghgAwCCCGADAIFtGFwBwZ7Ht9HOH7XvX9hOH7RtYnRExAIBBBDEAgEEEMQCAQQQxAIBBBDEAgEEEMQCAQQQxAIBBBDEAgEEEMQCAQQQxAIBBBDEAgEEEMQCAQQQxAIBBBDEAgEEEMQCAQQQxAIBBBDEAgEEEMQCAQbaMLgAANrNtp587dP+7tp84dP8sxogYAMAgghgAwCCCGADAIIIYAMAgghgAwCCCGADAIOsSxKrqSVV1bVVdX1Wnr7D816rq6qq6vKourKoHzC37dlVdNn3tWI96AAA2g4U/R6yqDkryiiRPSHJjkkurakd3Xz3X7aNJlrr7q1X1S0l+K8nTp2Vf6+7jFq0DAGCzWY8RseOTXN/dN3T3N5O8IclJ8x26+13d/dVp9pIk91uH/QIAbGrrEcSOSvKpufkbp7bVPCvJX8zN37WqdlbVJVV18jrUAwCwKezX/+Koqn4+yVKSn5hrfkB331RVP5jkoqq6orv/aoV1T0tyWpIcffTR+6VeAIB9aT1GxG5Kcv+5+ftNbd+lqk5I8sIkT+7ub+xu7+6bpu83JHl3koettJPuPrO7l7p7aevWretQNgDAWOsRxC5NcmxVHVNVhyQ5Jcl3/fVjVT0sySszC2Gfm2s/rKoOnaaPSPLoJPMP+QMAHLAWvjXZ3bdU1XOSnJ/koCRndfdVVXVGkp3dvSPJy5LcI8mbqypJ/rq7n5zkwUleWVXfySwUbl/215YAAAesdXlGrLvPS3LesrYXz02fsMp6H0jy0PWoAQBgs/HJ+gAAgwhiAACDCGIAAIMIYgAAgwhiAACDCGIAAIMIYgAAgwhiAACDCGIAAIMIYgAAgwhiAACDCGIAAIMIYgAAgwhiAACDCGIAAIMIYgAAgwhiAACDCGIAAIMIYgAAgwhiAACDCGIAAIMIYgAAgwhiAACDCGIAAIMIYgAAgwhiAACDCGIAAIMIYgAAgwhiAACDCGIAAIMIYgAAgwhiAACDCGIAAIMIYgAAg2wZXQDAetl2+rlD979r+4lD9w9sPkbEAAAGEcQAAAYRxAAABhHEAAAGEcQAAAYRxAAABhHEAAAGEcQAAAYRxAAABhHEAAAGEcQAAAYRxAAABlmXIFZVT6qqa6vq+qo6fYXlh1bVG6flH6yqbXPLXjC1X1tV/2w96gEA2AwWDmJVdVCSVyT550kekuQZVfWQZd2eleSL3f2gJC9P8pvTug9JckqSH03ypCS/N20PAOCAtx4jYscnub67b+jubyZ5Q5KTlvU5KcnZ0/Rbkjy+qmpqf0N3f6O7P5Hk+ml7AAAHvC3rsI2jknxqbv7GJI9crU9331JVf5fkPlP7JcvWPWqlnVTVaUlOS5Kjjz56Hcres22nn7vP97Enu7afuMflG7m+tWofbSMfu2RsfRu5tmTt+jb6e28j17fRX9uNXN9Gfl2TjX3sko19zdsfNs3D+t19ZncvdffS1q1bR5cDALCw9QhiNyW5/9z8/aa2FftU1ZYk90ry+du5LgDAAWk9gtilSY6tqmOq6pDMHr7fsazPjiSnTtNPTXJRd/fUfsr0V5XHJDk2yYfWoSYAgA1v4WfEpme+npPk/CQHJTmru6+qqjOS7OzuHUl+P8kfVdX1Sb6QWVjL1O9NSa5OckuSf93d3160JgCAzWA9HtZPd5+X5LxlbS+em/56kqetsu5Lk7x0PeoAANhMNs3D+gAABxpBDABgEEEMAGAQQQwAYBBBDABgEEEMAGAQQQwAYBBBDABgkHX5QNcD0Ub4H9kBgAObETEAgEEEMQCAQQQxAIBBBDEAgEEEMQCAQQQxAIBBBDEAgEEEMQCAQQQxAIBBBDEAgEEEMQCAQQQxAIBBBDEAgEG2jC4A2Dx2bT9xdAkABxQjYgAAgwhiAACDCGIAAIMIYgAAgwhiAACDCGIAAIMIYgAAgwhiAACDCGIAAIMIYgAAgwhiAACDCGIAAIMIYgAAgwhiAACDCGIAAIMIYgAAgwhiAACDCGIAAIMIYgAAg2wZXQDsb7u2nzi6BABIYkQMAGAYQQwAYBC3JmGDcesU4M5joRGxqjq8qi6oquum74et0Oe4qrq4qq6qqsur6ulzy15TVZ+oqsumr+MWqQcAYDNZ9Nbk6Uku7O5jk1w4zS/31SS/0N0/muRJSX6nqu49t/zXu/u46euyBesBANg0Fg1iJyU5e5o+O8nJyzt098e7+7pp+m+SfC7J1gX3CwCw6S0axO7b3Z+epj+T5L576lxVxyc5JMlfzTW/dLpl+fKqOnTBegAANo01H9avqncm+f4VFr1wfqa7u6p6D9s5MskfJTm1u78zNb8gswB3SJIzkzw/yRmrrH9aktOS5Oijj16rbACADW/NINbdJ6y2rKo+W1VHdvenp6D1uVX63TPJuUle2N2XzG1792jaN6rqD5I8bw91nJlZWMvS0tKqgQ8AYLNY9NbkjiSnTtOnJnnr8g5VdUiSc5L8YXe/ZdmyI6fvldnzZVcuWA8AwKaxaBDbnuQJVXVdkhOm+VTVUlW9eurzM0kek+SZK3xMxeuq6ookVyQ5IslvLFgPAMCmsdAHunb355M8foX2nUmePU2/NslrV1n/cYvsHwBgM/NfHAEADCKIAQAMIogBAAwiiAEADCKIAQAMIogBAAwiiAEADCKIAQAMIogBAAwiiAEADCKIAQAMIogBAAwiiAEADCKIAQAMIogBAAwiiAEADCKIAQAMIogBAAwiiAEADCKIAQAMIogBAAwiiAEADCKIAQAMIogBAAwiiAEADCKIAQAMIogBAAwiiAEADCKIAQAMIogBAAwiiAEADCKIAQAMIogBAAwiiAEADCKIAQAMIogBAAwiiAEADLJldAEAjLdr+4mjS4A7JSNiAACDCGIAAIMIYgAAgwhiAACDCGIAAIMIYgAAgwhiAACDCGIAAIMsFMSq6vCquqCqrpu+H7ZKv29X1WXT14659mOq6oNVdX1VvbGqDlmkHgCAzWTREbHTk1zY3ccmuXCaX8nXuvu46evJc+2/meTl3f2gJF9M8qwF6wEA2DQWDWInJTl7mj47ycm3d8WqqiSPS/KWO7I+AMBmt2gQu293f3qa/kyS+67S765VtbOqLqmqk6e2+yT5UnffMs3fmOSoBesBANg01vxPv6vqnUm+f4VFL5yf6e6uql5lMw/o7puq6geTXFRVVyT5u70ptKpOS3Jakhx99NF7syoAwIa0ZhDr7hNWW1ZVn62qI7v701V1ZJLPrbKNm6bvN1TVu5M8LMmfJLl3VW2ZRsXul+SmPdRxZpIzk2RpaWm1wAcAbCK7tp84uoShFr01uSPJqdP0qUneurxDVR1WVYdO00ckeXSSq7u7k7wryVP3tD4AwIFq0SC2PckTquq6JCdM86mqpap69dTnwUl2VtXHMgte27v76mnZ85P8WlVdn9kzY7+/YD0AAJvGmrcm96S7P5/k8Su070zy7Gn6A0keusr6NyQ5fpEaAAA2K5+sDwAwiCAGADCIIAYAMIggBgAwiCAGADCIIAYAMIggBgAwyEKfIwYA+8Od/b/B4cBlRAwAYBBBDABgEEEMAGAQQQwAYBBBDABgEEEMAGAQQQwAYBBBDABgEEEMAGAQQQwAYBBBDABgEEEMAGAQQQwAYBBBDABgEEEMAGAQQQwAYBBBDABgEEEMAGAQQQwAYBBBDABgEEEMAGAQQQwAYBBBDABgEEEMAGAQQQwAYBBBDABgEEEMAGAQQQwAYBBBDABgEEEMAGAQQQwAYBBBDABgEEEMAGAQQQwAYBBBDABgEEEMAGAQQQwAYBBBDABgkIWCWFUdXlUXVNV10/fDVujz2Kq6bO7r61V18rTsNVX1ibllxy1SDwDAZrLoiNjpSS7s7mOTXDjNf5fufld3H9fdxyV5XJKvJnnHXJdf3728uy9bsB4AgE1j0SB2UpKzp+mzk5y8Rv+nJvmL7v7qgvsFANj0Fg1i9+3uT0/Tn0ly3zX6n5Lk9cvaXlpVl1fVy6vq0AXrAQDYNLas1aGq3pnk+1dY9ML5me7uquo9bOfIJA9Ncv5c8wsyC3CHJDkzyfOTnLHK+qclOS1Jjj766LXKBgDY8NYMYt19wmrLquqzVXVkd396Clqf28OmfibJOd39rblt7x5N+0ZV/UGS5+2hjjMzC2tZWlpaNfABAGwWi96a3JHk1Gn61CRv3UPfZ2TZbckpvKWqKrPny65csB4AgE1j0SC2PckTquq6JCdM86mqpap69e5OVbUtyf2TvGfZ+q+rqiuSXJHkiCS/sWA9AACbxpq3Jvekuz+f5PErtO9M8uy5+V1Jjlqh3+MW2T8AwGbmk/UBAAYRxAAABhHEAAAGEcQAAAYRxAAABhHEAAAGEcQAAAYRxAAABhHEAAAGEcQAAAYRxAAABhHEAAAGWeg//WacXdtPHF0CALAgI2IAAIMIYgAAgwhiAACDCGIAAIMIYgAAgwhiAACDCGIAAIMIYgAAgwhiAACDCGIAAIMIYgAAgwhiAACDCGIAAIMIYgAAgwhiAACDCGIAAIMIYgAAgwhiAACDCGIAAIMIYgAAgwhiAACDCGIAAIMIYgAAgwhiAACDCGIAAINsGV0AALDv7Np+4ugS2AMjYgAAgwhiAACDCGIAAIMIYgAAgwhiAACDCGIAAIMIYgAAgwhiAACDLBTEquppVXVVVX2nqpb20O9JVXVtVV1fVafPtR9TVR+c2t9YVYcsUg8AwGay6IjYlUn+RZL3rtahqg5K8ook/zzJQ5I8o6oeMi3+zSQv7+4HJflikmctWA8AwKaxUBDr7mu6+9o1uh2f5PruvqG7v5nkDUlOqqpK8rgkb5n6nZ3k5EXqAQDYTPbHM2JHJfnU3PyNU9t9knypu29Z1r6iqjqtqnZW1c6bb755nxULALC/rPmfflfVO5N8/wqLXtjdb13/klbW3WcmOTNJlpaWen/tFwBgX1kziHX3CQvu46Yk95+bv9/U9vkk966qLdOo2O52AIA7hf1xa/LSJMdOfyF5SJJTkuzo7k7yriRPnfqdmmS/jbABAIy26MdXPKWqbkzyqCTnVtX5U/sPVNV5STKNdj0nyflJrknypu6+atrE85P8WlVdn9kzY7+/SD0AAJtJzQamNpelpaXeuXPn6DIAANZUVR/u7hU/b9Un6wMADCKIAQAMsilvTVbVzUk+ObqONRyR5G9HF7EHG7m+jVxbor5FbOTako1d30auLVHfIjZybYn61sMDunvrSgs2ZRDbDKpq52r3gzeCjVzfRq4tUd8iNnJtycaubyPXlqhvERu5tkR9+5pbkwAAgwhiAACDCGL7zpmjC1jDRq5vI9eWqG8RG7m2ZGPXt5FrS9S3iI1cW6K+fcozYgAAgxgRAwAYRBDjgFdV966qf7VO2/q3c9PbqurK9djuAvW8pqqeunbPf+i/X2ququdW1TVV9bqqet6+3t8iqupXqup79uH2/+H9V1U/WVVv28v19+o1nltvr/e1GVTVl1dpv0PHaY19PbOqfnedtvXuqtq0f9k3wqhzZ38TxLgzuHeS2wSxqtpyB7b1b9fuQmbH+wlJrtvfO66Zvbm2/UqSfRbEssr7D1jTvXMnOHcEsTuoqv6sqj5cVVdV1WlT27Oq6uNV9aGqetXu36SqamtV/UlVXTp9PXo/1Hf3qjq3qj5WVVdW1dOr6uFV9Z6p7vOr6siquldVXVtVPzyt9/qq+t/3dX3Lav2Fqrp8qvWPpt9i/ltV7ZyO5/+64C62J3lgVV02Hf/3VdWOJFdX1UFV9bKp/fKq+j+mmo6sqvdO61xZVf9zVW1Pcrep7XXTtrdMoz7XVNVbdo+sVNWuqvqtqrpiej88aGp/2rS9j1XVexc9VlPzY6rqA1V1w+7f/qYw8rJpX1dU1dMXPIZ7U+N/S/KDSf4iya8m+SdVdXFVXbf7vbXS8V1wn9um9/EfJrkyyb+be03/76nPSufEc5P8QJJ3VdW7pn5PnOr9SFW9uaruMbU/YjrOH5te0++tqu+pqjdV1dVVdU5VfbBuO+rxD++/JC9Lco/pvfKX03unpu2/eKr5yqo6c3f7sp9zxT5V9aCqeudU20eq6oHTKivua41j+fPTz3dZVb2yqh45Hce7Tsfwqqr6R1V1j6q6cNrfFVV10txrcU3NroFXVdU7qupuc8fw8mnbL6s1Rmer6temn/XKqvqVZcuqqn53et3fmeT75patdv6teC2uquOn1/yj02v8wyvUcuLU54jbcQxv815btvwZU21XVtVvzrV/uapePh23C6tq69T+wKp6e82u3e+rqh9Zq4ZF1G2vyT81vbc/Or3P7rsv9z9n3c6dDa27fd2BrySHT9/vltmF/6gku5IcnuTgJO9L8rtTnz9O8uPT9NFJrtkP9f10klfNzd8ryQeSbJ3mn57krGn6CUkuTnJKkrfv5+P4o0k+nuSI3cc1yWuSvD2zXxSOTXJjkrsusI9tSa6cpn8yyVeSHDPNn5bkRdP0oUl2Jjkmyf+V5IVT+0FJvnea/vKy7XaSR0/zZyV53jS9a279X0jytmn6iiRHTdP3Xqdj9ebpWD0kyfVzr/8FU+33TfLXSY6cPxb7+HXdldmnXb8kycem8+SIJJ/KLPiseHwXfI2/k+THkjwxs7+iqum4vC3JY1Y6J+ZrnaaPSPLeJHef5p+f5MVJDklyQ5JHTO33TLIlyfOSvHJq+0dJbkmytMb77++S3G+q7eLcem04fG6dP0ryU9P0a5I8dY0+H0zylGn6rpmN8K26rz0cxwcn+fMkB0/zvze9f38jyW8neUWSF0zLtiS559xxu3465tum43DctOxNSX5+mr4yyaOm6e17ei8meXhm58vdk9wjyVVJHpbpHEzyL3Lre/wHknxp7jjtysrn34rX4t2v5zR9QpI/maafmeR3kzwls2v6Ybfz/bjS9ffdSZamWv86ydbpGF6U5OSpXyf5uWn6xbn135ALkxw7TT8yyUX78Nxd6TpzWG79475nJ/lP+/oast7nzkb+uiO3Zph5blU9ZZq+f5J/meQ93f2FJKmqNyf5oWn5CUkeMhfS71lV9+juFZ91WCdXJPlP029bb0vyxcz+obhgquOgJJ9Oku6+oKqeltlF9p/sw5pW8rgkb+7uv51q+cJU35u6+ztJrquqG5L8SJLL1mmfH+ruT0zTT0zyj+vW5wjulVn4uzTJWVV1cJI/6+7V9v2p7n7/NP3aJM/N7B+sJHn93PeXT9PvT/KaqnpTkj/dy7pXO1Z/Nh2rq+d+U/3xJK/v7m8n+WxVvSfJI5Jcvpf7XA9v7e6vJflazUadjs/tP75745PdfUlV/XZmr+tHp/Z7ZPaavi9z50R3v2+FbfxYZoH2/dOxPSSzC/4PJ/l0d1+aJN39/ydJVf14kv93aruyqm7P8f1Qd984rX9ZZv/Y/Pckj62qf5NZiDo8s+Dx58vWvU2fqnp3ZuH+nKmOr0/b3tO+VvP4zALQpdP6d0vyuSRnZPaafT2z93gyC13/saoek1kIPiqz0J8kn5h7TT+cZFtV3TuzwH3x1P7HSfY02v3jSc7p7q9M9f9pkvmR08fk1vf431TVRcvWX+n8W/FanNl5f3ZVHZtZGDp4bjuPyyxAPXH36347fNf1t7vfN7fPRyR5d3ffPP1cr5t+lj/L7Di+cer32iR/OtX3PyV589w2Dr2dddwRK11nHprkjVV1ZGbnxCf2tIF9aJFzZ8MSxO6AqvrJzE7oR3X3V6cL4V9m9tvkSu6S5Md2XyD3h+7+eFX90yT/S2a/zV6U5KruftTyvjV7nubBSb6a2W8+N+6vOvdg+eeqrOfnrHxlbrqS/HJ3n7+80/QPzImZBaf/3N1/uMK29lTnbaa7+xer6pHTdj9cVQ/v7s/fkR9izjfmy15wW/vCbY5Rd7/3dh7fvbH7da0k/093v3J5h/lzoqou7O4zlndJckF3P2PZeg9dsLZ586/XtzO7vX3XzEaflrr7U1X1ksxGtuZrWLPP7dnXGv0rydnd/YJl+z4ys0B78LTPryT5ucxGdR7e3d+qql1z9Szf793W2O++sNK5uOK1uGaPkbyru59SVdsyG73a7a8yu9X+Q5mNmK+942XX36q68A79BLO675LkS9193B3cxnr4L0n+c3fvmP79e8mgOu7QubPReUbsjrlXki9OIexHMvst+u5JfqKqDqvZQ+A/Pdf/HUl+efdMVR23rwusqh9I8tXufm1m99YfmWRrVT1qWn5wVf3o1P1Xk1yT5GeT/ME0SrG/XJTkaVV1n6muw6f2p1XVXWr2rMsPJrl2gX38fZLvXWXZ+Ul+affPXFU/VLPnOx6Q5LPd/aokr07yT6f+31p2fI7efUwzO37zow1Pn/t+8bT9B3b3B7v7xUluzmw09fZa7Vit5H1Jnl6zZ+C2ZvYb94f2Yl/r6aSaPV90n8xuL1y6h+O7Hs5P8r/Vrc92HVVV37fCObF7n/Pvj0uSPLpufabo7lX1Q5m9/46sqkdM7d87nefvT/IzU9tDkqwU2Pb0/ttt9z8cfzvVvdJfeq3Yp7v/PsmNVXXyVMehdcf/CvTCJE+tqu+btnX49Fq9Msm/S/K6JLufabpXks9NIeyxSR6wpw1395eS/P30i0gyexRiT96X5OSaPYd399x6e3C39+bW9/iRSR67bP3bnH9Z/Vp8ryQ3TdPPXLadT2Z2Pf/DuWvmHu3hvZbMzsOfqKojquqgJM9I8p5p2V1y62v/s0n++zQK94ma3bXY/WzcvrxzsdJ1Zv74nLoP973cep07G5oRsTvm7Ul+saquyewCfUlmb9L/mNlJ9oXMRsj+bur/3CSvmG5bbMnsAvKL+7jGhyZ5WVV9J8m3kvxSZs9t/H9Vda+pjt+pqlsyu+d/fHf/fc0eIH9Rkn+/j+tLknT3VVX10iTvqapv59bbSX+d2bG8Z5JfXGQ0sbs/X1Xvr9mDwV9L8tm5xa/ObHj7IzUb9785ycmZBYZfr6pvJflyZs+ZJLNnjy6vqo8keWFmr/+/rqqzklyd5L/Obfuw6TX/RmYX22T2mhyb2cjDhZk9P3V7f47VjtVKzknyqGn7neTfdPdnpt/297fLk7wrs+eI/kN3/01VnZqVj+/CuvsdVfXgJBdPt3K+nOTnkzwotz0nktlr+vaq+pvufmxVPTPJ66tq9+2fF00jHE9P8l9q9uD51zIbFf+9zG5pXZ3ZOX9Vbj3vd9ezp/ff7j5fqqpXZfYM1Wcyuw24N33+ZZJXVtUZ08/2tL04ZPP7uLqqXpTkHTUbKf9Wkrcm+VZ3//EUHD5QVY/LLJT9eVVdkdlI0V/ejl08K8mrptfgPVl2rJbV8pGqek1u/QXi1d390br19tw5md1Guzqz68XFyzax0vm32rX4tzJ7HV+U5NwVavnLqvq5zG4P/lR3/9UaP+dK19/fnrb16ao6PbNzopKc291vndb7SpLjpzo+l1vD5M8l+a9T+8FJ3pC9uHbsjVWuMy/J7Gf/YmZB7Zh9se8ValmXc2ej88n666im576m35TPyexh+HNG17XZTBfft3X3W0bXckfV7DbN0u7nLDgwTcHk4O7++jR6+84kP9zd3xxc2oZUc8/GTmHkyO7+P/fBfnZlE55/VfXl7r7H6DrYv4yIra+XVNUJmQ2VviOzhy+BA9f3ZPbRFwdnNrrxr4SwPTqxql6Q2b89n8xtbwPCnY4RMQCAQTysDwAwiCAGADCIIAYAMIggBgAwiCAGADCIIAYAMMj/AP0j4QY/Ky0+AAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<Figure size 720x576 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.bar(df.columns[:-1], clf.coef_[0], figure=plt.figure(1, [10, 8]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I think the elements with the larger abs value means that those elements have more significane on the outcome of the predicion. I think this makes sense as we would expect certain attributes or symptoms to be more present in heart disease. Thus, this is what we are seeing in the graph."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
